{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Ingestion\n",
    "This step will load the dataset and allow you to preview the first few rows to get an understanding of its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1    536365     71053                  WHITE METAL LANTERN         6   \n",
      "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "\n",
      "      InvoiceDate  UnitPrice  Total  CustomerID         Country  \n",
      "0  12/1/2010 8:26       2.55  15.30     17850.0  United Kingdom  \n",
      "1  12/1/2010 8:26       3.39  20.34     17850.0  United Kingdom  \n",
      "2  12/1/2010 8:26       2.75  22.00     17850.0  United Kingdom  \n",
      "3  12/1/2010 8:26       3.39  20.34     17850.0  United Kingdom  \n",
      "4  12/1/2010 8:26       3.39  20.34     17850.0  United Kingdom  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the CSV file\n",
    "data = pd.read_csv(\"D:/Microsoft Data Engineer/Graduation Project/online_retail.csv\")\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Cleaning\n",
    "\n",
    "2.1. Handling Missing Values (CustomerID):\n",
    "Missing values are common in datasets like this. In e-commerce data, missing CustomerID is important because it's required for customer-level insights.\n",
    "\n",
    "\n",
    "Why: Missing CustomerID can lead to inaccurate customer insights (e.g., segmentation, personalization).\n",
    "Strategy: Remove rows with missing CustomerID, as those records won’t contribute meaningfully to customer-level analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InvoiceNo           0\n",
      "StockCode           0\n",
      "Description      1454\n",
      "Quantity            0\n",
      "InvoiceDate         0\n",
      "UnitPrice           0\n",
      "Total               0\n",
      "CustomerID     135080\n",
      "Country             0\n",
      "dtype: int64\n",
      "InvoiceNo      0\n",
      "StockCode      0\n",
      "Description    0\n",
      "Quantity       0\n",
      "InvoiceDate    0\n",
      "UnitPrice      0\n",
      "Total          0\n",
      "CustomerID     0\n",
      "Country        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Drop rows where CustomerID is missing\n",
    "data_clean = data.dropna(subset=['CustomerID'])\n",
    "\n",
    "# Confirm that no missing CustomerID values exist\n",
    "print(data_clean.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. Removing Duplicates:\n",
    "Duplicate records can skew data analysis, especially when counting transactions or total sales.\n",
    "\n",
    "Why: Duplicate entries can inflate sales, number of transactions, and other key metrics.\n",
    "Strategy: Remove all duplicate rows based on all columns to ensure only unique transactions are analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 5225\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows\n",
    "duplicates = data_clean.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n",
    "\n",
    "# Drop duplicate rows\n",
    "data_clean = data_clean.drop_duplicates()\n",
    "\n",
    "# Confirm duplicates are removed\n",
    "print(data_clean.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3. Handling Incorrect or Negative Quantities:\n",
    "Negative quantities typically indicate product returns, which may be useful, but in most cases, we filter them out for the purpose of sales analysis.\n",
    "\n",
    "Why: Negative quantities often reflect returns, which may skew sales metrics (like revenue or number of items sold).\n",
    "Strategy: Remove all transactions with negative quantities for standard sales analysis or keep them separate for return analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative quantity transactions: 8872\n",
      "Empty DataFrame\n",
      "Columns: [InvoiceNo, StockCode, Description, Quantity, InvoiceDate, UnitPrice, Total, CustomerID, Country]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check for negative quantities\n",
    "negative_quantities = data_clean[data_clean['Quantity'] < 0]\n",
    "print(f\"Number of negative quantity transactions: {len(negative_quantities)}\")\n",
    "\n",
    "# Remove rows where quantity is negative\n",
    "data_clean = data_clean[data_clean['Quantity'] > 0]\n",
    "\n",
    "# Confirm no negative quantities exist\n",
    "print(data_clean[data_clean['Quantity'] < 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4. Handling Invalid Stock Codes:\n",
    "Sometimes stock codes may be placeholders or invalid (e.g., codes that don’t match valid products). You can filter for valid stock codes.\n",
    "\n",
    "Why: Invalid stock codes often correspond to non-product-related transactions like charges, fees, or testing records.\n",
    "Strategy: Identify and filter out invalid stock codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['85123A' '71053' '84406B' ... '90214Z' '90089' '23843']\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Explore the unique stock codes to identify invalid ones\n",
    "print(data_clean['StockCode'].unique())\n",
    "\n",
    "# Example of filtering out invalid stock codes (replace 'INVALID' with any actual invalid codes identified)\n",
    "invalid_stock_codes = ['POST', 'D', 'M', 'DOT', 'BANK CHARGES', 'PADS', 'CRUK']\n",
    "\n",
    "data_clean = data_clean[~data_clean['StockCode'].isin(invalid_stock_codes)]\n",
    "\n",
    "# Confirm invalid stock codes are removed\n",
    "print(data_clean['StockCode'].isin(invalid_stock_codes).sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Ensuring Consistency and Final Checks:\n",
    "3.1. Fix Data Types:\n",
    "Ensure that the columns have the correct data types (e.g., dates should be in datetime format, numbers should be numeric).\n",
    "\n",
    "Why: Correct data types ensure that operations like date filtering, grouping, or aggregation work as expected.\n",
    "Strategy: Ensure dates are datetime objects, IDs are strings, and numeric values are in the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InvoiceNo              object\n",
      "StockCode              object\n",
      "Description            object\n",
      "Quantity                int64\n",
      "InvoiceDate    datetime64[ns]\n",
      "UnitPrice             float64\n",
      "Total                 float64\n",
      "CustomerID             object\n",
      "Country                object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert InvoiceDate to datetime format\n",
    "data_clean['InvoiceDate'] = pd.to_datetime(data_clean['InvoiceDate'])\n",
    "\n",
    "# Ensure CustomerID is a string\n",
    "data_clean['CustomerID'] = data_clean['CustomerID'].astype(str)\n",
    "\n",
    "# Confirm data types\n",
    "print(data_clean.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2. Recalculate Derived Columns:\n",
    "You might need to create or adjust derived columns, such as TotalPrice.\n",
    "\n",
    "Why: This provides a clearer view of transaction value, helping with sales forecasting and trend analysis.\n",
    "Strategy: Derive columns like TotalPrice to capture relevant transaction metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Quantity  UnitPrice  TotalPrice\n",
      "0         6       2.55       15.30\n",
      "1         6       3.39       20.34\n",
      "2         8       2.75       22.00\n",
      "3         6       3.39       20.34\n",
      "4         6       3.39       20.34\n"
     ]
    }
   ],
   "source": [
    "# Calculate total price for each transaction\n",
    "data_clean['TotalPrice'] = data_clean['Quantity'] * data_clean['UnitPrice']\n",
    "\n",
    "# Preview the result\n",
    "print(data_clean[['Quantity', 'UnitPrice', 'TotalPrice']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3. Final Checks and Exporting Cleaned Data:\n",
    "Once cleaning is done, export the cleaned data for use in the next steps (e.g., loading into a data warehouse or machine learning pipeline).\n",
    "\n",
    "Why: After cleaning, the data is ready for analysis, machine learning, or uploading to a cloud data warehouse (Azure SQL).\n",
    "Strategy: Save the cleaned dataset for easy access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 391316 entries, 0 to 541908\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   InvoiceNo    391316 non-null  object        \n",
      " 1   StockCode    391316 non-null  object        \n",
      " 2   Description  391316 non-null  object        \n",
      " 3   Quantity     391316 non-null  int64         \n",
      " 4   InvoiceDate  391316 non-null  datetime64[ns]\n",
      " 5   UnitPrice    391316 non-null  float64       \n",
      " 6   Total        391316 non-null  float64       \n",
      " 7   CustomerID   391316 non-null  object        \n",
      " 8   Country      391316 non-null  object        \n",
      " 9   TotalPrice   391316 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(3), int64(1), object(5)\n",
      "memory usage: 32.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Final check on the cleaned data\n",
    "print(data_clean.info())\n",
    "\n",
    "# Export cleaned data to CSV\n",
    "data_clean.to_csv('D:/Microsoft Data Engineer/Graduation Project/cleaned_online_retail.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
